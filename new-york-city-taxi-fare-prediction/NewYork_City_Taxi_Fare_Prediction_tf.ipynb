{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zwBCE43Cv3PH"
   },
   "source": [
    "## New York City Taxi Fare Prediction\n",
    "### Can you predict a rider's taxi fare?\n",
    "<br>\n",
    "<br>\n",
    "This is one of the Kaggle Competition for biginner, alredy completed.<br>\n",
    "Even it is very simple and straitforward for estimation, i thought it will be a good example to practice estimation problem from the scrath. <br>\n",
    "\n",
    "You can refer to here for details, https://www.kaggle.com/c/new-york-city-taxi-fare-prediction <br>\n",
    "This is a tensorflow code I made for your reference,\n",
    "Your task is to create PyTorch code and run your own code, and compare it with other competitions.\n",
    "\n",
    "If you have any questions on this implementaion, email [me](jychoi.ethan@gmail.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5IoRbCA2n0_V"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "#!pip install -q tensorflow==2.0.0-beta1\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-2kBGy_pxn47"
   },
   "source": [
    "## Read data using pandas\n",
    "set path of the csv file containing the heart dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VS4w2LePn9g3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_s.csv',\n",
       " '.DS_Store',\n",
       " 'NewYork_City_Taxi_Fare_Prediction_tf.ipynb',\n",
       " 'test.csv',\n",
       " 'submission.csv',\n",
       " 'GCP-Coupons-Instructions.rtf',\n",
       " 'train.csv',\n",
       " '.ipynb_checkpoints',\n",
       " 'make_train_s.ipynb',\n",
       " 'sample_submission.csv',\n",
       " 'NewYork_City_Taxi_Fare_Prediction.ipynb']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir('./')\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6BXRPD2-xtQ1"
   },
   "source": [
    "### The train file is too large and only 10% of the samples are imported for this training.\n",
    "```\n",
    "# the original size of train data is 55423856, about 55M\n",
    "df = df_train.sample(frac=0.1, replace=True, random_state=1)\n",
    "print('The size of train data =', len(df))\n",
    "\n",
    "df.to_csv('./train_s.csv')\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please download pre-created train_s file which samples 10% of the original file randomly\n",
    "**train_s.csv file download** \n",
    "[train_s.csv](https://drive.google.com/uc?export=download&id=1AbO1jfrwJ0IKSJQactC6msPNub131LAh)\n",
    "<br>**test.csv file download**\n",
    "[test_s.csv](https://drive.google.com/uc?export=download&id=1iE_JilybsBIBpaTveD6vX8AfwaZzI8i8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the csv file using pandas.<br>\n",
    "Instead of using original train.csv file, use smaller version, train_s.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_csv_file = './train.csv'\n",
    "train_csv_file = './train_s.csv'\n",
    "test_csv_file = './test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's read csv data into pandas dataframe\n",
    "It will take some time to load as train.csv is a bit huge, please be patient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UEfJ8TcMpe-2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of train data = 5542386\n",
      "The size of test = 9914\n",
      "The types of data = fare_amount          float64\n",
      "pickup_datetime       object\n",
      "pickup_longitude     float64\n",
      "pickup_latitude      float64\n",
      "dropoff_longitude    float64\n",
      "dropoff_latitude     float64\n",
      "passenger_count        int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(train_csv_file, index_col=0)\n",
    "df_test = pd.read_csv(test_csv_file, index_col=0)\n",
    "print('The size of train data =', len(df_train))\n",
    "print('The size of test =', len(df_test))\n",
    "print('The types of data =', df_train.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's see what the data looks like**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-03-02 18:04:10.0000006</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2013-03-02 18:04:10 UTC</td>\n",
       "      <td>-73.988898</td>\n",
       "      <td>40.721670</td>\n",
       "      <td>-73.985762</td>\n",
       "      <td>40.768975</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-12 23:00:29.0000006</th>\n",
       "      <td>9.7</td>\n",
       "      <td>2009-06-12 23:00:29 UTC</td>\n",
       "      <td>-73.985116</td>\n",
       "      <td>40.742225</td>\n",
       "      <td>-73.998634</td>\n",
       "      <td>40.763971</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             fare_amount          pickup_datetime  \\\n",
       "key                                                                 \n",
       "2013-03-02 18:04:10.0000006         18.0  2013-03-02 18:04:10 UTC   \n",
       "2009-06-12 23:00:29.0000006          9.7  2009-06-12 23:00:29 UTC   \n",
       "\n",
       "                             pickup_longitude  pickup_latitude  \\\n",
       "key                                                              \n",
       "2013-03-02 18:04:10.0000006        -73.988898        40.721670   \n",
       "2009-06-12 23:00:29.0000006        -73.985116        40.742225   \n",
       "\n",
       "                             dropoff_longitude  dropoff_latitude  \\\n",
       "key                                                                \n",
       "2013-03-02 18:04:10.0000006         -73.985762         40.768975   \n",
       "2009-06-12 23:00:29.0000006         -73.998634         40.763971   \n",
       "\n",
       "                             passenger_count  \n",
       "key                                           \n",
       "2013-03-02 18:04:10.0000006                1  \n",
       "2009-06-12 23:00:29.0000006                3  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocess\n",
    "- Drop columns not to be used for features, rows which has NaN values\n",
    "- Remove outliers\n",
    "- apply MinMaxScaler if possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fare_amount           0\n",
      "pickup_datetime       0\n",
      "pickup_longitude      0\n",
      "pickup_latitude       0\n",
      "dropoff_longitude    33\n",
      "dropoff_latitude     33\n",
      "passenger_count       0\n",
      "dtype: int64 pickup_datetime      0\n",
      "pickup_longitude     0\n",
      "pickup_latitude      0\n",
      "dropoff_longitude    0\n",
      "dropoff_latitude     0\n",
      "passenger_count      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Let's look over train data if there are Nan in any of features\n",
    "print(df_train.isnull().sum() , df_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove missing values\n",
    "df_train = df_train.dropna(how = 'any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From [the starter code](https://www.kaggle.com/dster/nyc-taxi-fare-starter-kernel-simple-linear-model) \n",
    "\n",
    "Add columns\n",
    "\n",
    "```\n",
    "# Given a dataframe, add two new features 'abs_diff_longitude' and\n",
    "# 'abs_diff_latitude' reprensenting the \"Manhattan vector\" from\n",
    "# the pickup location to the dropoff location.\n",
    "def add_travel_vector_features(df):\n",
    "    df['abs_diff_longitude'] = (df.dropoff_longitude - df.pickup_longitude).abs()\n",
    "    df['abs_diff_latitude'] = (df.dropoff_latitude - df.pickup_latitude).abs()\n",
    "\n",
    "add_travel_vector_features(train_df)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_travel_vector_features(df):\n",
    "    df['abs_diff_longitude'] = (df.dropoff_longitude - df.pickup_longitude).abs()\n",
    "    df['abs_diff_latitude'] = (df.dropoff_latitude - df.pickup_latitude).abs()\n",
    "\n",
    "# add longitude, latitude difference to column features\n",
    "add_travel_vector_features(df_train)\n",
    "add_travel_vector_features(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering out outliers\n",
    "From the starter code<br>\n",
    "\"We expect most of these values to be very small (likely between 0 and 1) since it should all be differences between GPS coordinates within one city. For reference, one degree of latitude is about 69 miles. However, we can see the dataset has extreme values which do not make sense. Let's remove those values from our training set. Based on the scatterplot, it looks like we can safely exclude values above 5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[(df_train.abs_diff_longitude < 5.0) & (df_train.abs_diff_latitude < 5.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of train data = 5530809\n",
      "The size of test = 9914\n",
      "The types of data = fare_amount           float64\n",
      "pickup_datetime        object\n",
      "pickup_longitude      float64\n",
      "pickup_latitude       float64\n",
      "dropoff_longitude     float64\n",
      "dropoff_latitude      float64\n",
      "passenger_count         int64\n",
      "abs_diff_longitude    float64\n",
      "abs_diff_latitude     float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "## Let's see the size of data again now\n",
    "print('The size of train data =', len(df_train))\n",
    "print('The size of test =', len(df_test))\n",
    "print('The types of data =', df_train.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set columns to drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df_train, df_test, cols_to_drop='', label='fare_amount'):\n",
    "    \"\"\"\n",
    "    Returns df_train_x, df_train_y, df_test_x\n",
    "    \"\"\"\n",
    "    drop_cols = []\n",
    "    for col in cols_to_drop:\n",
    "        if col in df_train:\n",
    "            drop_cols.append(col)\n",
    "\n",
    "    train_x = df_train.drop(columns=drop_cols)\n",
    "    train_y = train_x.pop(label)\n",
    "    \n",
    "    test_x = df_test.drop(columns=drop_cols)\n",
    "\n",
    "    return (train_x, train_y), test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to drop in input features\n",
    "# simply not to use pickup_datetime as a feature for estimation here.\n",
    "COLUMNS_TO_DROP = ['pickup_datetime', 'pickup_longitude', 'pickup_latitude', \\\n",
    "                   'dropoff_longitude', 'dropoff_latitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fare_amount', 'pickup_datetime', 'pickup_longitude',\n",
       "       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
       "       'passenger_count', 'abs_diff_longitude', 'abs_diff_latitude'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y), test_x = \\\n",
    "        preprocess_data(df_train, df_test, COLUMNS_TO_DROP, 'fare_amount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2wwhILm1ycSp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5530809, 3) (5530809,) (9914, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape, train_y.shape, test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>abs_diff_longitude</th>\n",
       "      <th>abs_diff_latitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-03-02 18:04:10.0000006</th>\n",
       "      <td>1</td>\n",
       "      <td>0.003136</td>\n",
       "      <td>0.047305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-12 23:00:29.0000006</th>\n",
       "      <td>3</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>0.021746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             passenger_count  abs_diff_longitude  \\\n",
       "key                                                                \n",
       "2013-03-02 18:04:10.0000006                1            0.003136   \n",
       "2009-06-12 23:00:29.0000006                3            0.013518   \n",
       "\n",
       "                             abs_diff_latitude  \n",
       "key                                             \n",
       "2013-03-02 18:04:10.0000006           0.047305  \n",
       "2009-06-12 23:00:29.0000006           0.021746  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's find out min, max values of each columns in train, test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_min = train_x.min(axis=0)\n",
    "train_x_max = train_x.max(axis=0)\n",
    "test_x_min = test_x.min(axis=0)\n",
    "test_x_max = test_x.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min = train_x_min.combine(test_x_min, min)\n",
    "x_max = train_x_max.combine(test_x_max, max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passenger_count       208.000000\n",
       "abs_diff_longitude      4.989833\n",
       "abs_diff_latitude       4.941050\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passenger_count       0.0\n",
       "abs_diff_longitude    0.0\n",
       "abs_diff_latitude     0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _MinMaxScaler(X, s_min, s_max, feature_range=(0, 1)):\n",
    "    \n",
    "    min, max = feature_range\n",
    "    \n",
    "    episilon = 1e-10\n",
    "    X_std = (X - s_min) / (s_max - s_min + episilon)\n",
    "    X_scaled = X_std * (max - min) + min\n",
    "    \n",
    "    return X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply MinMaxScaler to train and test dataframe\n",
    "(This is optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_x = _MinMaxScaler(train_x, x_min, x_max)\n",
    "#test_x = _MinMaxScaler(test_x, x_min, x_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>abs_diff_longitude</th>\n",
       "      <th>abs_diff_latitude</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-03-02 18:04:10.0000006</th>\n",
       "      <td>1</td>\n",
       "      <td>0.003136</td>\n",
       "      <td>0.047305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-06-12 23:00:29.0000006</th>\n",
       "      <td>3</td>\n",
       "      <td>0.013518</td>\n",
       "      <td>0.021746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             passenger_count  abs_diff_longitude  \\\n",
       "key                                                                \n",
       "2013-03-02 18:04:10.0000006                1            0.003136   \n",
       "2009-06-12 23:00:29.0000006                3            0.013518   \n",
       "\n",
       "                             abs_diff_latitude  \n",
       "key                                             \n",
       "2013-03-02 18:04:10.0000006           0.047305  \n",
       "2009-06-12 23:00:29.0000006           0.021746  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data using `tf.data.Dataset`\n",
    "\n",
    "Use tf.data.Dataset.from_tensor_slices to read the values from a pandas dataframe.\n",
    "\n",
    "One of the advantages of using tf.data.Dataset is it allows you to write simple, highly efficient data pipelines. Read the loading data guide to find out more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6Yc-D3aqyBb"
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((train_x.values, train_y.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "chEnp_Swsf0a"
   },
   "source": [
    "For reading<br>\n",
    "```for feat, targ in dataset.take(2):\n",
    "       print ('Features: {}, Target: {}'.format(feat, targ))```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9XLxRHS10Ylp"
   },
   "source": [
    "Shuffle and batch the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R3dQ-83Ztsgl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 3), (None,)), types: (tf.float64, tf.float64)>\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset.shuffle(len(train_x)).batch(BATCH_SIZE)\n",
    "print(train_dataset)\n",
    "_, input_size = train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bB9C0XJkyQEk"
   },
   "source": [
    "## Create and train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compiled_model(hidden_units, activation='relu', lr=1e-3, l2_scale=1e-3):\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    for units in hidden_units:\n",
    "        model.add(tf.keras.layers.Dense(units, \\\n",
    "                activation=activation, kernel_regularizer=tf.keras.regularizers.l2(l2_scale)))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(1, activation='relu', \\\n",
    "                        kernel_regularizer=tf.keras.regularizers.l2(l2_scale)))\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ybDzNUheqxJw"
   },
   "outputs": [],
   "source": [
    "model = get_compiled_model([input_size, 16, 8], lr=1e-3, l2_scale=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ybDzNUheqxJw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "43210/43210 [==============================] - 100s 2ms/step - loss: 47.6746 - mae: 3.4343\n",
      "Epoch 2/2\n",
      "43210/43210 [==============================] - 95s 2ms/step - loss: 43.5171 - mae: 2.7183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb2f100160>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just run 2 times as a trial\n",
    "model.fit(train_dataset, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                multiple                  12        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  64        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  9         \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_x.values))\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model predict for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fare_predict = model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of fare_predict= 9914\n",
      "the shape= (9914, 1)\n"
     ]
    }
   ],
   "source": [
    "print('the size of fare_predict=', len(fare_predict))\n",
    "print('the shape=', fare_predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9914,) (9914,)\n"
     ]
    }
   ],
   "source": [
    "fare_predict = fare_predict.reshape(-1)\n",
    "key = df_test.index.values\n",
    "print(key.shape, fare_predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the predictions to a CSV file which we can submit to the competition.\n",
    "submission = pd.DataFrame(\n",
    "    {'key': df_test.index, 'fare_amount': fare_predict},\n",
    "    columns = ['key', 'fare_amount'])\n",
    "submission.to_csv('submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pandas.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "1XwmbuQRh8Xo93CV_op6Q_ty2TAjGoBjc",
     "timestamp": 1558919304199
    }
   ],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
